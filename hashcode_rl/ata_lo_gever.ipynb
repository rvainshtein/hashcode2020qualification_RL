{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from gym.wrappers import TimeLimit\n",
    "from env import LibrariesEnv\n",
    "data_files = glob('data/qualification_round_2020.in/*.txt')\n",
    "data_file = data_files[0]  # example\n",
    "\n",
    "train_env = LibrariesEnv(data_file)\n",
    "train_env = TimeLimit(train_env, train_env.total_days)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x1d22c28fed0>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 1234\n",
    "\n",
    "train_env.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "input_dim = train_env.observation_space.shape[0] * train_env.observation_space.shape[1]\n",
    "hidden_dim = 32\n",
    "output_dim = train_env.action_space.n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run: 0:   0%|          | 0/300 [00:00<?, ?it/s]C:\\Users\\rvain\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:130: UserWarning: Error detected in SoftmaxBackward. Traceback of forward call that caused the error:\n",
      "  File \"C:\\Users\\rvain\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\rvain\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\rvain\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\rvain\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\rvain\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\rvain\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\rvain\\anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\rvain\\anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\rvain\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\rvain\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"C:\\Users\\rvain\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\Users\\rvain\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\rvain\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"C:\\Users\\rvain\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"C:\\Users\\rvain\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\rvain\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"C:\\Users\\rvain\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\rvain\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n",
      "    self.do_execute(\n",
      "  File \"C:\\Users\\rvain\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\rvain\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\rvain\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\rvain\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2877, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\rvain\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2923, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\rvain\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\rvain\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3146, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\rvain\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\rvain\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-6-4713eda69c05>\", line 20, in <module>\n",
      "    loss, train_reward = train(train_env, policy, optimizer, discount_factor, device)\n",
      "  File \"C:\\Users\\rvain\\anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\", line 26, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\dev\\repos\\hashcode_rl\\utils.py\", line 43, in train\n",
      "    action_prob = F.softmax(action_pred, dim=-1)\n",
      "  File \"C:\\Users\\rvain\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\", line 1512, in softmax\n",
      "    ret = input.softmax(dim)\n",
      " (Triggered internally at  ..\\torch\\csrc\\autograd\\python_anomaly_mode.cpp:104.)\n",
      "  Variable._execution_engine.run_backward(\n",
      "Run: 0:   0%|          | 0/300 [00:19<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [2]], which is output 0 of SoftmaxBackward, is at version 1; expected version 0 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-6-4713eda69c05>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     18\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mepisode\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtqdm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmax_episodes\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdesc\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34mf'Run: {run}'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 20\u001B[1;33m         \u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_reward\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_env\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpolicy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdiscount_factor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     21\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_env\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0maction_space\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtaken_actions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001B[0m in \u001B[0;36mdecorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     24\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     25\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 26\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     27\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mcast\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mF\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\dev\\repos\\hashcode_rl\\utils.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(env, policy, optimizer, discount_factor, device)\u001B[0m\n\u001B[0;32m     64\u001B[0m     \u001B[0mreturns\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcalculate_returns\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrewards\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdiscount_factor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 66\u001B[1;33m     \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mupdate_policy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mreturns\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlog_prob_actions\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     67\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     68\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepisode_reward\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\dev\\repos\\hashcode_rl\\utils.py\u001B[0m in \u001B[0;36mupdate_policy\u001B[1;34m(returns, log_prob_actions, optimizer)\u001B[0m\n\u001B[0;32m     92\u001B[0m     \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 94\u001B[1;33m     \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     95\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     96\u001B[0m     \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(self, gradient, retain_graph, create_graph)\u001B[0m\n\u001B[0;32m    219\u001B[0m                 \u001B[0mretain_graph\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    220\u001B[0m                 create_graph=create_graph)\n\u001B[1;32m--> 221\u001B[1;33m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    222\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    223\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001B[0m\n\u001B[0;32m    128\u001B[0m         \u001B[0mretain_graph\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    129\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 130\u001B[1;33m     Variable._execution_engine.run_backward(\n\u001B[0m\u001B[0;32m    131\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    132\u001B[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001B[1;31mRuntimeError\u001B[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [2]], which is output 0 of SoftmaxBackward, is at version 1; expected version 0 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "n_runs = 5\n",
    "max_episodes = 300\n",
    "discount_factor = 0.99\n",
    "\n",
    "train_rewards = torch.zeros(n_runs, max_episodes)\n",
    "test_rewards = torch.zeros(n_runs, max_episodes)\n",
    "device = torch.device('cpu')\n",
    "\n",
    "for run in range(n_runs):\n",
    "\n",
    "    policy = MLP(input_dim, hidden_dim, output_dim)\n",
    "    policy = policy.to(device)\n",
    "    policy.apply(init_weights)\n",
    "    optimizer = optim.Adam(policy.parameters(), lr=1e-2)\n",
    "\n",
    "    for episode in tqdm.tqdm(range(max_episodes), desc=f'Run: {run}'):\n",
    "\n",
    "        loss, train_reward = train(train_env, policy, optimizer, discount_factor, device)\n",
    "        print(train_env.action_space.taken_actions)\n",
    "\n",
    "        train_rewards[run][episode] = train_reward"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x432 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idxs = range(max_episodes)\n",
    "fig, ax = plt.subplots(1, figsize=(10,6))\n",
    "plt.axhline(y=train_env.scores.sum())\n",
    "ax.plot(idxs, train_rewards.mean(0))\n",
    "# ax.fill_between(idxs, train_rewards.min(0).values, train_rewards.max(0).values, alpha=0.1)\n",
    "ax.set_xlabel('Steps')\n",
    "ax.set_ylabel('Rewards');"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([119.9333, 102.1000, 120.0000, 102.0233, 102.6000])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rewards.mean(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[107., 113., 120.,  ..., 120., 120., 120.],\n        [120., 114., 102.,  ..., 102., 102., 102.],\n        [120., 120., 120.,  ..., 120., 120., 120.],\n        [109., 102., 102.,  ..., 102., 102., 102.],\n        [102., 102., 102.,  ..., 102., 102., 102.]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rewards"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001B[1;32mc:\\users\\rvain\\anaconda3\\lib\\site-packages\\torch\\distributions\\categorical.py\u001B[0m(107)\u001B[0;36msample\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m    105 \u001B[1;33m            \u001B[0msample_shape\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msample_shape\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[0m\u001B[1;32m    106 \u001B[1;33m        \u001B[0mprobs_2d\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprobs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_events\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[0m\u001B[1;32m--> 107 \u001B[1;33m        \u001B[0msamples_2d\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmultinomial\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprobs_2d\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_shape\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mT\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[0m\u001B[1;32m    108 \u001B[1;33m        \u001B[1;32mreturn\u001B[0m \u001B[0msamples_2d\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_extended_shape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msample_shape\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[0m\u001B[1;32m    109 \u001B[1;33m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%debug\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-76d7199d",
   "language": "python",
   "display_name": "PyCharm (hashcode_rl)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}